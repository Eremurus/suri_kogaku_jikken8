{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "suri_jikken8_33_kai.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3cs-2LbuHBFC",
        "outputId": "0a361dab-f7c3-4f09-9cbd-faa472867c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 32)        2432      \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 32)        25632     \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 64)        51264     \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 8, 8, 64)          102464    \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 2, 2, 64)          200768    \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 152)               39064     \n",
            "                                                                 \n",
            " multivariate_normal_tri_l_3  ((None, 16),             0         \n",
            "  (MultivariateNormalTriL)    (None, 16))                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 421,624\n",
            "Trainable params: 421,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_2 (Reshape)         (None, 1, 1, 16)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_12 (Conv2D  (None, 7, 7, 64)         50240     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_13 (Conv2D  (None, 7, 7, 64)         102464    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_14 (Conv2D  (None, 14, 14, 64)       102464    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_15 (Conv2D  (None, 14, 14, 32)       51232     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_16 (Conv2D  (None, 28, 28, 32)       25632     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_17 (Conv2D  (None, 28, 28, 32)       25632     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 28, 28, 1)         801       \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " independent_bernoulli_2 (In  ((None, 32, 32, 3),      0         \n",
            " dependentBernoulli)          (None, 32, 32, 3))                 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 358,465\n",
            "Trainable params: 358,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 32)        2432      \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 32)        25632     \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 64)        51264     \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 8, 8, 64)          102464    \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 2, 2, 64)          200768    \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 152)               39064     \n",
            "                                                                 \n",
            " multivariate_normal_tri_l_3  ((None, 16),             0         \n",
            "  (MultivariateNormalTriL)    (None, 16))                        \n",
            "                                                                 \n",
            " sequential_6 (Sequential)   (None, 32, 32, 3)         358465    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 780,089\n",
            "Trainable params: 780,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e23822b8700a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m             loss=negloglik)\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfignum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 200704 values, but the requested shape has 786432\n\t [[node model_1/sequential_6/independent_bernoulli_2/IndependentBernoulli/Reshape\n (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:724)\n]] [Op:__inference_train_function_131155]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_1/sequential_6/independent_bernoulli_2/IndependentBernoulli/Reshape:\nIn[0] model_1/sequential_6/flatten_6/Reshape (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/core/flatten.py:96)\t\nIn[1] model_1/sequential_6/independent_bernoulli_2/IndependentBernoulli/concat (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:721)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-4-e23822b8700a>\", line 115, in <module>\n>>>     history = vae.fit(train_dataset, epochs=10, validation_data=eval_dataset)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/layers/distribution_layer.py\", line 221, in __call__\n>>>     inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/layers/distribution_layer.py\", line 227, in call\n>>>     inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/layers/core/lambda_layer.py\", line 196, in call\n>>>     result = self.function(inputs, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/layers/distribution_layer.py\", line 166, in _fn\n>>>     d = make_distribution_fn(*fargs, **fkwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/layers/distribution_layer.py\", line 700, in <lambda>\n>>>     t, event_shape, sample_dtype, validate_args),\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/layers/distribution_layer.py\", line 724, in new\n>>>     logits=tf.reshape(params, new_shape),\n>>> "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "tfk = tf.keras\n",
        "tfkl = tfk.layers\n",
        "from tensorflow.keras import layers, models, initializers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import tensorflow_probability as tfp#tensorflow_probabilityは長いのでtfpとして簡略化してimport\n",
        "#分布の省略も準備する\n",
        "tfd = tfp.distributions\n",
        "tfpl = tfp.layers\n",
        "\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "#データセットの準備\n",
        "import tensorflow_datasets as tfds\n",
        "datasets, datasets_info = tfds.load(name='cifar10', with_info=True,\n",
        "                                    as_supervised=False)\n",
        "\n",
        "def _preprocess(sample):\n",
        "  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
        "  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n",
        "  return image, image\n",
        "\n",
        "train_dataset = (datasets['train']\n",
        "                 .map(_preprocess)\n",
        "                 .batch(256)\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "                 .shuffle(int(10e3)))\n",
        "eval_dataset = (datasets['test']\n",
        "                .map(_preprocess)\n",
        "                .batch(256)\n",
        "                .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "encoded_size = 16 #圧縮時のサイズを設定\n",
        "base_depth = 32 #フィルター数\n",
        "#学習パラメータのない独立した平均0,分散1の正規分布乱数をencoded_size個作成\n",
        "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
        "                        reinterpreted_batch_ndims=1)\n",
        "\n",
        "encoder = models.Sequential([\n",
        "    tfkl.InputLayer(input_shape= (32, 32, 3)),\n",
        "    #tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\n",
        "    #今回は画像の畳み込みを使用するに当たって\n",
        "    #一般に画像はRGB画像のように、RGBの3つのレイヤーを持つので、(縦, 横, レイヤー)の\n",
        "    #入力に変換する必要がある。\n",
        "    #今回のグレースケール画像なら、余分にレイヤーを加え、(28,28,1)の形式に変換する\n",
        "    tfkl.Conv2D(base_depth, 5, strides=1,\n",
        "                padding='same', activation=tf.nn.leaky_relu),\n",
        "    #【layers.Conv2Dの説明】\n",
        "    #base_depthはフィルターで生成される画像の数\n",
        "    #5の引数は畳み込みをするフィルターのサイズ\n",
        "    #stride はピクセル間の隙間のピクセル数を制御\n",
        "    #conv1では（28,28,2）が出力になる。\n",
        "    #これは1枚の入力画像に対して、28×28ピクセルの画像が2つ出力されることを意味する\n",
        "    tfkl.Conv2D(base_depth, 5, strides=2,\n",
        "                padding='same', activation=tf.nn.leaky_relu),\n",
        "    tfkl.Conv2D(2 * base_depth, 5, strides=1,\n",
        "                padding='same', activation=tf.nn.leaky_relu),\n",
        "    tfkl.Conv2D(2 * base_depth, 5, strides=2,\n",
        "                padding='same', activation=tf.nn.leaky_relu),\n",
        "    tfkl.Conv2D(4 * encoded_size, 7, strides=1,\n",
        "                padding='valid', activation=tf.nn.leaky_relu),\n",
        "    tfkl.Flatten(),\n",
        "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),#多変量正規分布の混合\n",
        "               activation=None),\n",
        "    tfpl.MultivariateNormalTriL(\n",
        "        encoded_size,\n",
        "        activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n",
        "])\n",
        "#エンコーダと事前確率との間の KL ダイバージェンスを正則化項として追加する\n",
        "#weightを 1 以外のものに変えるだけで、この VAE を β-VAE に変更できる\n",
        "encoder.summary()\n",
        "\n",
        "decoder = tfk.Sequential([\n",
        "    tfkl.InputLayer(input_shape=[encoded_size]),\n",
        "    tfkl.Reshape([1, 1, encoded_size]),\n",
        "    tfkl.Conv2DTranspose(2 * base_depth, 7, strides=1,\n",
        "                         padding='valid', activation=tf.nn.leaky_relu),\n",
        "                          # (1,1,16)->(7,7,64)に膨らむ\n",
        "                          # base_depth = 32 はフィルター数\n",
        "                          # 出力画像サイズは7\n",
        "                          # padding がvalid ならパディングをしない\n",
        "                          # output_shape = (input_shape-1)×strides+filter_shape=(1-1)×1+7\n",
        "    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=1,\n",
        "                         padding='same', activation=tf.nn.leaky_relu),\n",
        "                          # padding が same でゼロパディング\n",
        "                          # output_shape = input_shape×strides=7×1\n",
        "    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=2,\n",
        "                         padding='same', activation=tf.nn.leaky_relu),\n",
        "    tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n",
        "                         padding='same', activation=tf.nn.leaky_relu),\n",
        "    tfkl.Conv2DTranspose(base_depth, 5, strides=2,\n",
        "                         padding='same', activation=tf.nn.leaky_relu),\n",
        "    tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n",
        "                         padding='same', activation=tf.nn.leaky_relu),\n",
        "    tfkl.Conv2D(filters=1, kernel_size=5, strides=1,\n",
        "                padding='same', activation=None),\n",
        "    tfkl.Flatten(),\n",
        "    tfpl.IndependentBernoulli((32, 32, 3), tfd.Bernoulli.logits),\n",
        "])\n",
        "#ピクセル間で独立したベルヌーイ分布にする\n",
        "decoder.summary()\n",
        "\n",
        "vae = tfk.Model(inputs=encoder.inputs,\n",
        "                outputs=decoder(encoder.outputs[0]))\n",
        "vae.summary()\n",
        "\n",
        "negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n",
        "\n",
        "vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
        "            loss=negloglik)\n",
        "\n",
        "history = vae.fit(train_dataset, epochs=10, validation_data=eval_dataset)\n",
        "\n",
        "def display_imgs(x, title=None, fignum=None):\n",
        "  import matplotlib.pyplot as plt  # pylint: disable=import-outside-toplevel,g-import-not-at-top\n",
        "  if not tf.executing_eagerly():\n",
        "    raise NotImplementedError('`display_imgs` can only be executed eagerly.')\n",
        "  def _preprocess(z):\n",
        "    return np.array(getattr(z, 'numpy', lambda: z)())\n",
        "  x = _preprocess(x)\n",
        "  if title is not None:\n",
        "    title = _preprocess(title)\n",
        "  x = np.reshape(x, (-1,) + x.shape[-4:])\n",
        "  nrows, ncols, h, w, c = x.shape\n",
        "  x = np.reshape(np.transpose(x, [0, 2, 1, 3, 4]), [nrows * h, ncols * w, c])\n",
        "  plt.ioff()\n",
        "  subplots_kwargs = dict(\n",
        "      nrows=1,\n",
        "      ncols=1,\n",
        "      figsize=(ncols, max(2, nrows)),\n",
        "      num=fignum,\n",
        "      clear=True)\n",
        "  try:\n",
        "    fig, axs = plt.subplots(**subplots_kwargs)\n",
        "  except TypeError:\n",
        "    subplots_kwargs.pop('clear')\n",
        "    fig, axs = plt.subplots(**subplots_kwargs)\n",
        "  axs.imshow(x.squeeze(), interpolation='none')\n",
        "  axs.axis('off')\n",
        "  if title is not None:\n",
        "    axs.set_title(str(title))\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "  plt.ion()\n",
        "  return fig, axs\n",
        "\n",
        "  x = next(iter(eval_dataset))[0][:10]\n",
        "xhat = vae(x)\n",
        "assert isinstance(xhat, tfd.Distribution)\n",
        "print('元の画像:')\n",
        "display_imgs(x)\n",
        "\n",
        "print('デコーダの乱数:')\n",
        "display_imgs(xhat.sample())\n",
        "\n",
        "print('デコーダ最頻値:')\n",
        "display_imgs(xhat.mode())\n",
        "\n",
        "print('デコーダ平均値:')\n",
        "display_imgs(xhat.mean())"
      ]
    }
  ]
}